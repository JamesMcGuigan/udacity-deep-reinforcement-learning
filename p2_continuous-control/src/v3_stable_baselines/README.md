# Stable Baselines

- https://towardsdatascience.com/5-frameworks-for-reinforcement-learning-on-python-1447fede2f18
- https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html
- https://github.com/araffin/rl-tutorial-jnrr19
- https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/1_getting_started.ipynb#scrollTo=gWskDE2c9WoN


As an alternative to implementing all our own algorithms from scratch, 
it is possible to use a library implementation instead. Stable Baselines was chosen for this example.

Strangely, this code was able to successfully loop, but training failed to converge and this
achieved similar performance to both RandomBot and hand-coded Actor Critic implementations.
